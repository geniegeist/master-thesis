\chapter{Classification with Fundamental Models}

In this chapter, we introduce \emph{reduced} and \emph{fundamental models} to classify discrete statistical models with rational MLE; this classification is due to Bik and Marigliano \cite{bik2022classifying}. 

\section{Parametrization}

First, we establish a parametrization for discrete statistical models with rational MLE, which is crucial for the classification of statistical models.

\begin{proposition}\label{prop:parametrization}
    Let \( \mathcal{M} \) be a one-dimensional discrete statistical models with rational MLE. Then, there exists a map of the form \( p: [0,1] \to \Delta_n, \theta \mapsto (w_k \theta^{i_k} (1-\theta)^{j_k})_{k=0}^n \) with \( i_k, j_k \in \mathbb{Z}_{\geq 0} \), \( w_k \in \mathbb{R}_{> 0} \) such that \( \mathcal{M} = \mathrm{image}(p) \).
\end{proposition}

We introduce some notation to simplify the proof of Proposition \ref{prop:parametrization}.
Let \( \mathcal{M} \subset \Delta_n \) be a one-dimensional discrete statistical model parametrized by rational functions \( p_0 =  \frac{g_0}{h_0}, \dots, p_n =  \frac{g_n}{h_n} \). Define \( b \coloneqq \mathrm{lcm}(h_0, \dots, h_n) \) and \( a_i \coloneqq b p_i \). Then, we multiply \( \sum_{k=0}^n p_k = 1 \) by \( b \) to obtain \( \sum_{k=0}^n a_k = b \). We use these polynomials \( a_0, \dots, a_n \) and \( b \) to determine the statistical model \( \mathcal{M} \). The log-likelihood function then reads
\begin{align*}
    \ell(p) = \sum_{k=0}^n u_k \log p_k = \sum_{k=0}^n u_k \log \frac{a_k}{b} = \sum_{k=0}^n u_k \log a_k - \sum_{k=0}^n u_k \log b.
\end{align*}
To find the maximum likelihood estimator, we find all critical points of the log-likelihood function, which is equivalent to finding the critical points of
\begin{align}\label{eq:score-equations}
    \ell(p(\theta))' &= \sum_{k=0}^n u_k \frac{a_k'}{a_k} - \sum_{k=0}^n u_k \frac{b'}{b} = 0.
\end{align}
These equations are called the \emph{score equations} in algebraic statistics.

\begin{definition}
    The number of complex solutions to the score equations for general data \( u \in \mathbb{C}^{n + 1} \) is called the \emph{maximum likelihood degree} (ML degree) of the statistical model. 
\end{definition}


This ML degree has an important meaning in algebraic statistics, as it is an algebraic measure of the complexity of the maximum likelihood estimation of the model \cite{amendola2019maximum, catanese2006maximum, sullivant2023algebraic}. We have the following relationship between MLE and ML degree.

\begin{proposition}\label{prop:rational-mle}
    A statistical model has rational maximum likelihood estimator if and only if the maximum likelihood degree of the model is one.
\end{proposition}

\begin{proof}
   Refer to \cite{duarte2021discrete} for a proof.
\end{proof}

Next, we need the following lemma to prove Proposition \ref{prop:parametrization},

\begin{lemma}\label{lem:two-complex-factors}
    Let \( \mathcal{M} \) be a one-dimensional discrete statistical models with rational MLE. Then, there exist exactly two distinct complex linear factors in \( a_0, \dots, a_n \), and \( b \).
\end{lemma}

\begin{proof}
    We prove the lemma in three steps:
    \begin{itemize}
        \item Let \( f \) be the product of all distinct complex linear factors in \( a_0, \dots, a_n\), and \( b \).  First, we multiply the score equations \eqref{eq:score-equations} by \( f \) to get \( f  \ell(p(\theta))' = \sum_{k=0}^n u_k f \frac{a_k'}{a_k} - \sum_{k=0}^n u_k f \frac{b'}{b} = 0 \).
        Note that every linear factor of \( a_k \) with multiplicity \( m \) occurs in \( a_k' \) with multiplicity \( m-1 \). Thus, \( \frac{a_k'}{a_k} = \frac{\lambda}{(x-\xi)} \) holds, where \( \lambda \in \mathbb{R} \) and \( x-\xi \) is some linear factor of \( a_k \). Hence, \( f \cdot  \frac{\lambda}{(x-\xi)}  \) is of degree \( \mathrm{deg}(f) - 1\). Therefore, \( f \ell(p(\theta))' \) is of degree \( \mathrm{deg}(f) - 1\).

        \item We claim that the roots of \( \ell(p(\theta))' \) are the same as the roots of \( f  \ell(p(\theta))' \). Assume that we have established this claim.  By Proposition \ref{prop:rational-mle}, the ML degree is one. So, \( \ell(p(\theta))' \) has one root. Thus, \( f  \ell(p(\theta))' \) has one root. Therefore, \( f  \ell(p(\theta))' \) is of degree one. This implies that \( \mathrm{deg}(f) = 2 \). Thus, there are exactly two distinct complex linear factors in \( a_0, \dots, a_n \), and \( b \).
        
        \item It remains to show that the roots of \( \ell(p(\theta))' \) are the same as the roots of \( f  \ell(p(\theta))' \). Clearly, every root of \( \ell(p(\theta))' \) is a root of \( f  \ell(p(\theta))' \). Conversely, we want to show that no new roots are introduced when multiplying by \( f \), i.e. roots of \( f \) are not roots of \(  f \cdot \ell(p(\theta))' \). Let us rewrite \( f  \ell(p(\theta))' = \sum_{k=0}^n u_k f \frac{a_k'}{a_k} - \sum_{k=0}^n u_k f \frac{b'}{b} = \sum_{k=0}^{n + 1} v_k f \frac{c_k'}{c_k} \)
        with \( v_k \coloneqq u_k, c_k \coloneqq a_k  \) for \( k=0, \dots,n \), and \(  v_{n+1} \coloneqq - \sum_{k=0}^n u_k \), \( c_{n+1} \coloneqq b \).

        Let \( q \) be a complex linear factor of \( f \). We define polynomials \( r_0, \dots, r_{n+1} \) and \( r \) such that \( c_k = q^{l_k}r_k \), \( f = q r \) hold, and \( r_0, \dots, r_{n+1}, r \) do not have \( q \) as a factor. Then, we have
        \begin{align*}
            f \frac{c_k'}{c_k} = q r \cdot \frac{l_k q^{l_k - 1} q'r_k +  q^{l_k}r_k'}{q^{l_k}r_k} = q r\frac{l_k q' }{q} + q r\frac{r_k'}{r_k} \equiv rl_k q' \pmod q
        \end{align*}
        for \(  k = 0, \dots, n+1 \).
        Thus, we obtain \( f \cdot \ell(p(\theta))' \equiv rq'\sum_{k=0}^{n + 1} v_k l_k \equiv rq' \sum_{k=0}^{n } v_k(l_k - l_{n+1}) \pmod q \).
        Note that by definition of \( l_k \), a value of \( l_k = 0 \) means that \( q \) is not a factor of \( c_k \). By definition of \( f \), at least one \( l_k \) is strictly positive. On the other hand, not all \( l_k \) can be strictly positive since \( a_0, \dots, a_n\), and \(b \) share no common factors. Hence, not all \( l_k - l_{n+1} \) vanish. Hence, for generic data \( u \) we assume \( \sum_{k=0}^{n } v_k(l_k - l_{n+1}) \neq 0 \). This with \( q'r \not \equiv 0 \pmod q \) implies that \( q \) is not a complex linear factor of \( f  \ell(p(\theta))' \). We showed that the roots of \( f \) are not roots of \( f \cdot \ell(p(\theta))' \).
    \end{itemize}
\end{proof}

We now prove Proposition \ref{prop:parametrization}.

\begin{proof}
    First, we show that \( I \) is a single closed real interval and not a union of closed intervals. For the sake of contradiction, assume that \( I = \bigcup_{k} I_k \) is a union of closed disjoint intervals. By definition of \( \mathcal{M} \), we know that \( p(\partial I) \subset \partial \Delta_n \). Thus, there exist \( \theta_1, \theta_2 \in \partial I_0 \) and \( \theta_3, \theta_4 \in \partial I_1 \) with \( p_i(\theta_1) = p_i(\theta_2) =  0 \) and \( p_j(\theta_3) = p_j(\theta_4) = 0 \) for some \( i,j = 0, \dots, n \). Note that \( \theta_1 \) and \( \theta_2 \) are roots of \( \frac{a_i}{b} \); similarly,  \( \theta_3 \) and \( \theta_4 \) are roots of \( \frac{a_j}{b} \). By Lemma \ref{lem:two-complex-factors}, exactly two distinct complex linear factors occur in \( a_0, \dots, a_n \), and \( b \). Hence, \( \theta_3 = \theta_1 \) or \( \theta_3 = \theta_2 \) holds. We found a contradiction for \( I_0 \) and \( I_1 \) are disjoint.

    We established that \( I = [\alpha, \beta ]\) is a real single closed interval. Thus, the roots of \( a_0, \dots, a_n\), and \( b \) are real and take values in \( \partial I = \left\{ \alpha, \beta \right\} \). By a suitable parametrization, we assume \( I = [0,1] \). Next, we write the polynomials \( a_0, \dots, a_n\), and \( b \) as \(  a_k(\theta) = w_k \theta^{i_k} (1-\theta)^{j_k} \) and \( b(\theta) = w \theta^{i} (1-\theta)^{j} \)
    with \( w_k, w \in \mathbb{R}_{>0} \), and \( i_k, j_k, i, j \in \mathbb{Z}_{\geq 0} \). Since \( a_0, \dots, a_n\), and \( b \) share no common factors, there exists some \( i_k = 0 \) if \( i > 0 \); however, this contradicts \(0 < w_k \leq a_0(0) + \dots + a_n(0) = b(0) = 0\). So, \( i = 0 \) holds. Similarly, we have \( j = 0 \). Finally, we divide \( p \) by \( w \) to obtain \( b \equiv 1 \).
\end{proof}

\begin{corollary}
    Any one-dimensional {discrete} {statistical} {models} with rational MLE can be represented by \( (w_k, i_k, j_k)_{k=0}^n \) for \( w_k \in \mathbb{R}_{>0} \) and \( i_k, j_k \in \mathbb{Z}_{\geq 0} \).
\end{corollary}

\begin{definition}
    The degree \( \mathrm{deg}(\mathcal{M}) \) of a one-dimensional discrete statistical models with rational MLE \( \mathcal{M} \) represented by \( (w_k, i_k, j_k)_{k=0}^n \) is defined as \( \mathrm{max}\left\{ i_k + j_k : k = 0, \dots, n \right\} \).
\end{definition}

\begin{remark}\label{rem:equivalent-models}
    We view two models \( (w_k,i_k,j_k)_{k=0}^n \) and \( (w_k',i_k',j_k')_{k=0}^n \) as the same model if they are equal up to a permutation of the coordinates.
\end{remark}

\begin{example}
    The sequence \( ((1,0,2), (2,1,1), (1,2,0)) \) represents the binomial model with two trials. It has degree two. Its parametrization is given by \( \theta \mapsto ((1-\theta)^2, 2\theta(1-\theta),\theta^2) \). See Figure \ref{fig:binom-discrete-model} for a visualization of the binomial model within the probability simplex \( \Delta_2 \). Note that we treat \( ((1,0,2), (2,1,1), (1,2,0)) \), \( ((2,1,1), (1,0,2), (1,2,0)) \), and \( ((2,1,1), (1,2,0), (1,0,2)) \) as the same model, as coordinate order does not matter.
\end{example}

\begin{definition}
    Let \( \mathcal{M} \) be a model represented by \( (w_k, i_k, j_k)_{k=0}^n \). The set of exponent pairs \( (i_k, j_k)_{k=0}^n \) is called the support of \( \mathcal{M} \), denoted by \( \mathrm{supp}(\mathcal{M}) \).
\end{definition}

This was our first step towards understanding the structure of one-dimensional discrete statistical models with rational MLE. Next, we introduce reduced models.

\section{Reduced Models}

Models in this section refer to one-dimensional discrete statistical models with rational MLE.

\begin{definition}
    We call a model represented by \( (w_k, i_k, j_k)_{k=0}^n \) \emph{reduced} if \( (i_k, j_k) \neq \mathbf 0 \) for all \( k = 0, \dots, n \), and \( (i_k, j_k) \neq (i_l, j_l) \) for all \( k \neq l \).
\end{definition}

We use functions to represent reduced models due to \( (i_k, j_k) \neq (i_l, j_l) \).

\begin{remark}\label{rem:representation-of-models-by-functions}
    A reduced model \( \mathcal{M} \) represented by \( (w_k, i_k, j_k)_{k=0}^n \) is identified by a function \( f: \mathbb{Z}^2 \to \mathbb{R}_{\geq 0}, (i, j) \mapsto w \), where \( w = w_k \) if \( (i_k, j_k) = (i, j) \) and \( w = 0 \) otherwise. The support of \( f \) is the set of all pairs \( (i, j) \) with \( f(i, j) > 0 \). It coincides with the support of \( \mathcal{M} \).
\end{remark}


Reduced models are our first building blocks for the classification of statistical models because the following two propositions show that non-reduced models are transformed into a reduced model by a sequence of linear embeddings.

\begin{proposition}\label{prop:linear-embedding-1}
    Let \( n \in \mathbb{N}_{>0} \).
    Let \( \mathcal{M} \) be a model represented by \( (w_k, i_k, j_k)_{k=0}^n \). If \( (i_l, j_l) = \mathbf{0} \) for some index \( l \), then there exist a model \( \mathcal{M}' \), \( \lambda \in [0,1] \) and \( k = 0, \dots, n \) such that \( \mathcal{M} = \Psi_{\lambda,k}(\mathcal{M}') \), where \( \Psi_{\lambda, k}: \Delta_{n-1} \to \Delta_n \) is defined as \(  p_i \mapsto \begin{cases}
        \lambda p_i & \text{if } k \neq i, \\
        1-\lambda & \text{otherwise }
    \end{cases} \)
\end{proposition}

\begin{proof}
    Let \( (i_l, j_l) = \mathbf{0} \) for some index \( l \). If \( w_l = 1 \), then \( w_m = 0 \) for all \( m \neq l \); this contradicts \( w_m > 0 \) by Proposition \ref{prop:parametrization}. Set \( \lambda = 1 - w_l > 0 \) and \( k = l \). Define the model \( \mathcal{M}' \) represented by \( \left(\frac{w_h}{1-w_l}, i_h, j_h\right)^n_{h=0, h \neq l} \).
    Then, \( \mathcal{M} = \Psi_{\lambda,k}(\mathcal{M}') \).
\end{proof}

\begin{proposition}\label{prop:linear-embedding-2}
    Let \( n \in \mathbb{N}_{>0} \).
    Let \( \mathcal{M} \) be model represented by \( (w_k, i_k, j_k)_{k=0}^n \). If \( (i_m, j_m) = (i_l, j_l)  \) for \( m \neq l \), then there exist a model \( \mathcal{M}' \), \( \lambda \in [0,1] \) and \( k,h = 0, \dots, n \) such that \( \mathcal{M} = \Psi_{\lambda,k,h}(\mathcal{M}') \), 
    where \( \Psi_{\lambda, k,h}: \Delta_{n-1} \to \Delta_n \) is defined as \(  p_i \mapsto \begin{cases}
         p_i & \text{if } i \notin \left\{ k,h \right\}, \\
        \lambda p_k & \text{if } k = i, \\
        (1-\lambda) p_k & \text{if } h = i. \\
    \end{cases} \)
\end{proposition}

\begin{proof}
    Define \( \lambda = \frac{w_m}{w_m + w_l} \), \( k = m \), and \( h = l \). Define the model \( \mathcal{M}' \) represented by \(  \left( w_g + \delta_{gm}w_l, i_g, j_g  \right)^n_{g=0, g \neq l} \).
    Then, \( \mathcal{M} = \Psi_{\lambda,k}(\mathcal{M}') \).
\end{proof}

Repeated application of the two propositions transforms any model into a reduced model.

\begin{corollary}\label{cor:reduced-models}
    If \( \Delta_n \) contains a model of degree \( d \), then there also exists a reduced model of degree \( d \) in \( \Delta_m \) for some \( m \leq n \).
\end{corollary}


\section{Fundamental Models}

As before, models refer to one-dimensional discrete statistical models with rational MLE. The main building blocks for the classification of models are \emph{fundamental models}; we will see that reduced models come from fundamental models.

\begin{definition}\label{def:fundamental-model}
    We call a model represented by \( (w_k, i_k, j_k)_{k=0}^n \) \emph{fundamental} if it is reduced and the equation \( p_0 + \dots p_n \equiv 1 \) for given \( (i_k, j_k)_{k=0}^n \) uniquely determines the weights \( (w_k)_{k=0}^n \).
\end{definition}

\begin{example}
    The binomial model with two trials is fundamental. Given \( (i_0, j_0) = (0,2) \), \( (i_1, j_1) = (1,1) \), and \( (i_2, j_2) = (2,0) \), the equation \( p_0 + p_1 + p_2 = w_0\theta^2 + w_1\theta(1-\theta) + w_2(1-\theta)^2 \equiv 1 \) uniquely determines the weights \( w_0 = 1, w_1 = 2, w_2 = 1 \). To see this observe that this equation is equivalent to \( w_0\theta^2 + w_1\theta - w_1 \theta^2 + w_2 -w_22\theta + w_2\theta^2 = 1\) which is equivalent to solving \( w_2 - 1 + \theta(w_1 - 2w_2) + \theta^2(w_0 - w_1 + w_2) = 0 \) for all \( \theta \in \mathbb{R} \).
\end{example}

\begin{example}\label{ex:prob-simplex-0}
    Consider the probability simplex \( \Delta_0 \). It only contains the model \( 1 \) which is fundamental.
\end{example}

\begin{example}\label{ex:prob-simplex-1}
    Now, consider the probability simplex \( \Delta_1 \). It only contains the models \( \theta \mapsto (\theta, 1-\theta) \) and \( \theta \mapsto (1-\theta, \theta) \) which are equivalent. They are fundamental.
\end{example}

Fundamental models are the building blocks for all reduced models.

\begin{definition}
    Let \( \mathcal{M} \) and \( \mathcal{M}' \) be reduced models which are represented by functions \( f,g : \mathbb{Z}^2 \to \mathbb{R}_{\geq 0} \), see Remark \ref{rem:representation-of-models-by-functions}. Let \( \mu \in (0,1) \). The \emph{composite} \( \mathcal{M} *_\mu \mathcal{M}' \) of \( \mathcal{M} \) and \( \mathcal{M}' \) is the reduced model represented by the function \(  (i,j) \mapsto \mu f(i,j) + (1-\mu) g(i,j) \).
\end{definition}


% \begin{proposition}
%     Let \( \mathcal{M} \) be a reduced model. If \( \mathcal{M} \) is not the composite of two reduced models whose supports are proper subsets of \( \mathrm{supp}(\mathcal{M}) \), then \( \mathcal{M} \) is fundamental.
% \end{proposition}

% \begin{proof}
%     Let \( S \coloneqq \mathrm{supp}(\mathcal{M}) \) and let \( \mathcal{M} \) be represented by \( (v_k, i_k, j_k)_{k=0}^n \). The set of all reduced models with support equal to \( S \) corresponds to the set \( A \) of all real \( (w_k)_{k=0}^n \) that satisfy 
%     \begin{align*}
%         \sum_{k=0}^n w_k t^{i_k}(1-t)^{j_k} \equiv 1, \quad w_k \in \mathbb{R}.
%     \end{align*}
%     This set \( A \) contains \( v \). It is an affine-linear half-space, and its dimension coincides with the dimension of the linear space  \( \mathrm{lin}\{ t^{i_k}(1-t)^{j_k} : k=0, \dots, n\} \) since there exists an open ball around \( \mathbf v \) containing only positive vectors.

%     By assumption \( \mathcal{M} \) is the composite of two reduced models \( \mathcal{M}_1 \) and \( \mathcal{M}_2 \) with supports \( S_1 \) and \( S_2 \) which are proper subsets of \( S \).
% \end{proof}

\begin{proposition}\label{prop:composition-fundamental}
    Every reduced model is the finite composite of fundamental models.
\end{proposition}

\begin{proof}
    For \( \Delta_0 \) and \( \Delta_1 \) we know that they only contain fundamental models, see Examples \ref{ex:prob-simplex-0} and \ref{ex:prob-simplex-1}. 
    
    Assume we are given \( \Delta_n \) with \( n \geq 2 \), and let \( \mathcal{M} \) be a model that is not fundamental. We aim to show that \( \mathcal{M} \) can be expressed as a composite of two models, \( \mathcal{M}' \) and \( \mathcal{M}'' \), whose supports are proper subsets of \( \mathrm{supp}(\mathcal{M}) \). Assume this is indeed the case. Then, by applying the same argument to \( \mathcal{M}' \) and \( \mathcal{M}'' \), we can recursively decompose each non-fundamental model into models with smaller supports. Since \( \mathrm{supp}(\mathcal{M}) \) is finite, this recursive decomposition must eventually terminate, yielding a decomposition of \( \mathcal{M} \) into fundamental models. Thus, we have shown that any reduced model is the composite of a finite number of fundamental models. 

    Let us prove that \( \mathcal{M} \) is the composite of two models whose supports are proper subsets of \( \mathrm{supp}(\mathcal{M}) \). Since \( \mathcal{M} \) is not fundamental, the equation \( p_0 + \dots + p_n = 1 \) has distinct solutions \( \mathbf w, \mathbf w' \in \mathbb{R}^{n+1}_{> 0} \). Define \( \mathbf v \coloneqq \mathbf w - \mathbf w' \neq \mathbf 0 \). Then, for all \( \theta \in (0,1) \) we have \( \sum_{k=0}^n v_k \theta^{i_k}(1-\theta)^{j_k} = 0  \).
    Observe that there are strictly positive and negative coefficients \( v_k \). 
    
    Define \( \lambda \coloneqq \min \left\{ \frac{w_k}{\lvert v_k \rvert} : k = 0, \dots, n, \; v_k < 0 \right\} \), \( u_k \coloneqq w_k + \lambda v_k \) for \(k = 0, \dots, n \), and \( S_1 \coloneqq \left\{ (i_k, j_k) : k=0, \dots, n, \; u_k \neq 0 \right\} \). Note that \( \lambda > 0 \) since all the coefficients \( w_k \) are strictly positive by definition. Also observe that \( u_k \geq 0 \) if \( v_k \geq 0 \). Moreover, by definition \( \frac{w_k}{\lvert v_k \rvert} \geq \lambda \) for all \( k \geq 0 \). Hence, if \( v_k < 0 \), we also have \( \frac{u_k}{v_k} = \frac{w_k}{v_k} + \lambda  \leq 0\). Multiplying by \( v_k < 0 \) we obtain \( u_k \geq 0 \). All in all, we have \( u_k \geq 0 \) for all \( k = 0, \dots, n \). Moreover, \( u_k = 0 \) if and only if \( v_k < 0 \) and \( \lambda = \frac{w_k}{\lvert v_k \rvert} \). This shows that \( S_1 \subsetneq \mathrm{supp}(\mathcal{M}) \). Since \( u_0 + \dots u_n = 1 \), we have found a reduced model \( \mathcal{M}' \) represented by \( (u_k, i_k, j_k)_{(i_k,j_k) \in S_1} \).

    For the second model, we define
    \begin{align*}
        \mu &\coloneqq \min \left\{ \frac{w_k}{u_k} : k = 0, \dots, n, \; u_k \neq 0 \right\}, \\
        t_k &\coloneqq \frac{w_k - \mu u_k}{1 - \mu} \quad \text{for } k = 0, \dots, n, \\
        S_2 &\coloneqq \left\{ (i_k, j_k) : k=0, \dots, n, \; t_k \neq 0 \right\}.
    \end{align*}
    Similarly, \( \mu > 0 \). We have \( \mu < 1 \) because some \( v_k \) is positive implying \( u_k > w_k \). By definition, we have \( t_k \geq 0 \), and \( t_k = 0 \) if and only if \( u_k \neq 0 \) and \( \mu = \frac{w_k}{u_k} \). This shows that \( S_2 \subsetneq  \mathrm{supp}(\mathcal{M}) \) and \( S_1 \cup S_2 = \mathrm{supp}(\mathcal{M}) \). Since \( t_0 + \dots + t_n = 1 \), we have found a reduced model \( \mathcal{M}'' \) represented by \( (t_k, i_k, j_k)_{(i_k,j_k) \in S_2} \).

    Finally, we see that \( w_k = \mu u_k + (1-\mu) t_k\). This shows that \( \mathcal{M} = \mathcal{M}' *_\mu \mathcal{M}'' \).
\end{proof}

Applying the previous proposition with Corollary \ref{cor:reduced-models} yields the following corollary.

\begin{corollary}\label{cor:fundamental-models-ksmlkdf}
    If \( \Delta_n \) contains a non-fundamental model of degree \( d \), then there exists a fundamental model of degree \( d \) in \( \Delta_m \) for some \( m < n \).
\end{corollary}

\begin{example}
For the two-dimensional probability simplex \( \Delta_2 \), we can classify all models. Again, models refer to one-dimensional discrete statistical models with rational MLE. Note that the model \( \mathcal{M} \) parametrized by \( \theta \mapsto (\theta, 1-\theta) \) satisfies \( \mathcal{M} *_\mu \mathcal{M} = \mathcal{M} \) for all \( \mu \). Since \( \Delta_1 \) only contains the model \( \theta \mapsto (\theta, 1-\theta) \), we can conclude that \( \Delta_2 \) only contains fundamental models or models that are not reduced.

To find all the fundamental models in \( \Delta_2 \), we need to check for all sets \( S = \left\{ (i_k,j_k)\right\}_{k=0}^2 \subset \mathbb{Z}^2_{>0} \) of size three if the equation \( p_0 + p_1 + p_2 = \sum_{k=0}^2 w_k \theta^{i_k}(1-\theta)^{j_k} = 1 \) has a unique solution \( (w_0, w_1, w_2) \). As we can see, a priori infinitely many sets \( S \) need to be checked. However, as we will see in the next section, only those sets \( S \) with \( \max\left\{ i+j : (i,j) \in S \right\} \leq 2n -1 = 3 \) need to be considered. Clearly, this reduces the number of sets \( S \) to be checked to a finite number.

Only the supports \( \{ (0,3), (1,1), (3,0) \}\), \( \{ (0,2), (1,1), (2,0) \}\), \( \{ (0,1), (1,1), (2,0) \} \), and \( \{ (0,2),(1,0),(1,1) \} \) uniquely determine the weights \( (w_0, w_1, w_2) \). 
These supports correspond to the fundamental models \( ((1-\theta)^3, 3\theta(1-\theta), \theta^3) \), \( ((1-\theta)^2, 2\theta(1-\theta), \theta^2) \), \( (1-\theta, \theta(1-\theta), \theta^2) \), and \( ((1-\theta)^2, \theta, \theta(1-\theta)) \); note that the last model is equivalent to the third model by \( \theta \mapsto 1-\theta \) and a permutation of the coordinates.

\begin{figure}[H]
    \centering
    \includegraphics[width=0.8\textwidth]{assets/fundamental-models-delta-2.png}
    \caption{From left to right, the illustration depicts the models parametrized \( ((1-\theta)^3, 3\theta(1-\theta), \theta^3) \), \( ((1-\theta)^2, 2\theta(1-\theta), \theta^2) \), \( (1-\theta, \theta(1-\theta), \theta^2) \), and \( ((1-\theta)^2, \theta, \theta(1-\theta)) \).}

    \includegraphics[width=0.55\textwidth]{assets/non-red-models-delta-2.png}
    \caption{This illustration depicts two non-reduced models in \( \Delta_2 \) for \( \lambda = \frac{1}{3} \). They are parametrized by \( \theta \mapsto (\frac{2}{3}\theta, \frac{1}{3}, \frac{2}{3}(1 - \theta)) \) and \( \theta \mapsto (1-\theta, \frac{1}{3}\theta, \frac{2}{3}\theta) \). All other non-reduced models can be obtained by varying \( \lambda \).} 
\end{figure}

We just computed all fundamental models of degree three or less in \( \Delta_2 \). We will see shortly that these are all models in the probability simplex \( \Delta_2 \). Of course, \( \Delta_2 \) contains non-reduced models, too. These are models that come from linear embeddings \( \Psi_{\lambda,k} \) and \( \Psi_{\lambda,k,h} \), see Proposition \ref{prop:linear-embedding-1} and Proposition \ref{prop:linear-embedding-2}. There are infinitely many of them, and for \( \lambda = \frac{1}{3} \) we obtain the models \( \theta \mapsto (\frac{2}{3}\theta, \frac{1}{3}, \frac{2}{3}(1 - \theta)) \) and \( \theta \mapsto (1-\theta, \frac{1}{3}\theta, \frac{2}{3}\theta) \).
\end{example}

\begin{theorem}\label{thm:classification-jekns}
    Every one-dimensional discrete statistical model with rational MLE in \( \Delta_n \) is the image of a reduced model in \( \Delta_m \) under a linear embedding \( \Delta_m \to \Delta_n \) for some \( m \leq n \).

    Moreover, every reduced model \( \mathcal{M} \subset \Delta \) can be written as a composite of finitely many fundamental models \( \mathcal{M} = \mathcal{M}_1 *_{\mu_1} ( \dots *_{\mu_{m-2}}( \mathcal{M}_{m-1} *_{\mu_{m-1}} \mathcal{M}_m) ) \)
    for some \( m < n \) and \( \mu_1, \dots, \mu_m \in (0,1) \).
\end{theorem}

\begin{proof}
    See Proposition \ref{prop:composition-fundamental}, Proposition \ref{prop:linear-embedding-1}, and Proposition \ref{prop:linear-embedding-2}.
\end{proof}

\section{On the Finiteness of Fundamental Models}

After establishing that fundamental models serve as the building blocks for all models, we will prove that for \( n \leq 4 \), there are only finitely many fundamental models in \( \Delta_n \). This result was first established by Bik and Marigliano, and we adopt their approach. To begin, we present the following proposition.

\begin{theorem}\label{thm:degree-fundamental-models}
    Let \( \mathcal{M} \) be a one-dimensional discrete statistical model with rational MLE in \( \Delta_n \). For \(n \leq 4 \), we have \( \mathrm{deg}(\mathcal{M}) \leq 2n - 1\).
\end{theorem}

Given this theorem, it is easy to show the finiteness of fundamental models.

\begin{theorem}\label{thm:finiteness-fundamental-models}
    There are only finitely many fundamental models in \( \Delta_n \) for all \( n \leq 4 \).
\end{theorem}

\begin{proof}
    Let \( n \leq 4 \).
    By Theorem \ref{thm:degree-fundamental-models}, we know that the degree of a fundamental model is at most \( 2n - 1 \). Since the number of supports of a fundamental model of degree \( 2n - 1 \) is finite, there are only finitely many fundamental models in \( \Delta_n \).
\end{proof}

It turns out that proving Theorem \ref{thm:degree-fundamental-models} only for fundamental models is sufficient.

\begin{theorem}\label{thm:degree-fundamental-models-reduced}    
    Let \( N \in \mathbb{N} \). If the upper bound \( \mathrm{deg}(\mathcal{M}) \leq 2n - 1 \) holds for all \( n \leq N \) and for all fundamental models \( \mathcal{M} \in \Delta_n \), then this upper bound also holds for all statistical models, including non-fundamental ones, in \( \Delta_n \) for all \( n \leq N \).
\end{theorem}

\begin{proof}
    Let $N \in \mathbb{N}$ and $n \leq N$.
    Assume there is some non-fundamental model $\mathcal{M}'$ in $\Delta_n$ of degree greater than $2n - 1$. By Corollary \ref{cor:fundamental-models-ksmlkdf} there exists a fundamental model $\mathcal{M}$ in $\Delta_m$ for some $m < n$ of degree greater than $2m - 1$. This contradicts the assumption that the degree of fundamental models is at most $2n' - 1$ for all $n' \leq N$.
\end{proof}

This justifies that our north star is to prove the following theorem.

\begin{theorem}\label{thm:degree-fundamental-models-fundamental}
    Let \( \mathcal{M} \) be a fundamental model in \( \Delta_n \). For \(n \leq 4 \), we have \( \mathrm{deg}(\mathcal{M}) \leq 2n - 1\).
\end{theorem}

The first step is introducing a combinatorial puzzle to count fundamental models using the sequence \((w_k, i_k, j_k)_{k=0}^{n}\), which characterizes these models. 